# -*- coding: utf-8 -*-
"""midterm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c8TpQ3fc0kZ8aFJOSu0PDNIbgVsonQqw
"""

import numpy as np
import pandas as pd

val_file = pd.read_csv('val.csv')
train_file = pd.read_csv('train.csv')
test_file = pd.read_csv('test.csv')

front=1
back=64

#data clean ->Missing data
import seaborn as sns

cols = train_file.columns[:]
# specify the colours - yellow is missing. blue is not missing.
colours = ['#000099', '#ffff00'] 
sns.heatmap(train_file[cols].isnull(), cmap=sns.color_palette(colours))

# first create missing indicator for features with missing data
for col in train_file.columns:
    missing = train_file[col].isnull()
    num_missing = np.sum(missing)
    
    if num_missing > 0:  
        print('created missing indicator for: {}'.format(col))
        train_file['{}_ismissing'.format(col)] = missing


# then based on the indicator, plot the histogram of missing values
ismissing_cols = [col for col in train_file.columns if 'ismissing' in col]
train_file['num_missing'] = train_file[ismissing_cols].sum(axis=1)

train_file['num_missing'].value_counts().reset_index().sort_values(by='index').plot.bar(x='index', y='num_missing')

# drop rows with a lot of missing values.
ind_missing = train_file[train_file['num_missing'] > 1].index
df_less_missing_rows = train_file.drop(ind_missing, axis=0)
print(train_file)
df_less_missing_rows.head()

label=['bad', 'fair', 'good', 'Excellent']

train_clndata=df_less_missing_rows.iloc[:,front:back]
train_data = train_file.iloc[:,front:back]
print(train_clndata)

train_clndata = train_clndata.values

print('train_data shape = ',train_data.shape)
print('train_clndata shape =' ,train_clndata.shape)

train_clnlabel = df_less_missing_rows[['Label']].to_numpy()
train_clnlabel_num = [label.index(l) for l in train_clnlabel]

val_data = val_file.iloc[:,front:back]

val_data = np.nan_to_num(val_data,0)
# print(val_data)
val_label = val_file[['Label']].to_numpy()
#print(val_label)
val_label_num = [label.index(l) for l in val_label]
#print(val_label_num)

from sklearn.svm import SVC    #1. choose "Support vector claaifier"
model = SVC(kernel='rbf', gamma=0.0123, C=150)  # 2. instantiate model            #top     gamma=0.0123, C=150  score=0.8608064516129033
#model.fit(train_data, train_label.ravel())    # 3. fit model to data                  0.8603225806451613                                             
model.fit(train_clndata,train_clnlabel.ravel())
result = model.predict(val_data)        # 4. predict on new data

from sklearn.metrics import accuracy_score
score = accuracy_score(val_label, result)
print(score)

#score
from sklearn.metrics import accuracy_score
score = accuracy_score(val_label, result)
print(score)

test_data = test_file.iloc[:,front:back]
print(test_data)
test_data = test_data.values
print(test_data)

result = model.predict(test_data)               # 4. predict on new data
print(result)

label=['x','Excellent', 'good', 'fair', 'bad']
result_num = [label.index(l) for l in result]

index_num=[]
for i in range(86100):
    index_num.append(i)

#字典中的key值即為csv中列名
dataframe = pd.DataFrame({'index':index_num,'Label':result_num})
#將DataFrame儲存為csv,index表示是否顯示行名，default=True
dataframe.to_csv("midterm.csv",index=False,sep=',')

# #pca preprocessing
# train_stats0 = train_file.describe().loc[['mean','std']]
# train_stats0.style.format("{:.2f}")
# train_stats = train_stats0.iloc[:,0:-6]
# train_stats.style.format("{:.2f}")
# from sklearn.preprocessing import StandardScaler
# from numpy.testing import assert_almost_equal

# #train_data
# scaler = StandardScaler()
# Z_sk = scaler.fit_transform(train_data)

# #Z = (X - X.mean(axis=0)) / X.std(axis=0, ddof=0)
# Z = (train_data - train_data.mean(axis=0)) / train_data.std(axis=0, ddof=0)
# assert_almost_equal(Z,Z_sk)
# print(Z.shape)
# print(train_file.shape)
# print(train_file.iloc[:,1:-7].shape)
# train_file.iloc[:,1:-7]=Z
# train_stats0 = train_file.describe().loc[['mean','std']]
# train_stats0.style.format("{:.2f}")

# #64維度PCA降維成2D
# from sklearn.decomposition import PCA
# import matplotlib.pyplot as plt

# n_components = 2
# random_state = 6666

# pca = PCA(n_components=n_components,
#           random_state=random_state)
# L = pca.fit_transform(Z)

# plt.scatter(L[:,0],L[:,1])
# # plt.axis('1');

# # Validation Curve
# print(__doc__)

# import matplotlib.pyplot as plt
# import numpy as np

# from sklearn.datasets import load_digits
# from sklearn.svm import SVC
# from sklearn.model_selection import validation_curve

# # train_data, train_label = load_digits(return_X_y=True)

# param_range = np.logspace(-6, -1, 5)
# print(param_range)
# train_scores, test_scores = validation_curve(
#     SVC(), train_data, train_label, param_name="gamma", param_range=param_range,
#     scoring="accuracy", n_jobs=1)
# train_scores_mean = np.mean(train_scores, axis=1)
# train_scores_std = np.std(train_scores, axis=1)
# test_scores_mean = np.mean(test_scores, axis=1)
# test_scores_std = np.std(test_scores, axis=1)

# plt.title("Validation Curve with SVM")
# plt.xlabel(r"$\gamma$")
# plt.ylabel("Score")
# plt.ylim(0.0, 1.1)
# lw = 2
# plt.semilogx(param_range, train_scores_mean, label="Training score",
#              color="darkorange", lw=lw)
# plt.fill_between(param_range, train_scores_mean - train_scores_std,
#                  train_scores_mean + train_scores_std, alpha=0.2,
#                  color="darkorange", lw=lw)
# plt.semilogx(param_range, test_scores_mean, label="Cross-validation score",
#              color="navy", lw=lw)
# plt.fill_between(param_range, test_scores_mean - test_scores_std,
#                  test_scores_mean + test_scores_std, alpha=0.2,
#                  color="navy", lw=lw)
# plt.legend(loc="best")
# plt.show()

### GridSearchCV
# from sklearn.model_selection import train_test_split
# from sklearn.model_selection import GridSearchCV
# from sklearn.metrics import classification_report
# from sklearn.svm import SVC

# print(__doc__)

# # Loading the Digits dataset
# digits = datasets.load_digits()

# # To apply an classifier on this data, we need to flatten the image, to
# # turn the data in a (samples, feature) matrix:
# n_samples = len(digits.images)
# X = digits.images.reshape((n_samples, -1))
# y = digits.target

# # Split the dataset in two equal parts
# ###X_train, X_test, y_train, y_test = train_test_split(
# ###    X, y, test_size=0.5, random_state=0)

# # Set the parameters by cross-validation
# #[{'kernel': ['rbf'], 'gamma': [1e-3, 5e-2],'C': [1, 10, 100, 1000]}]
# C_range = np.logspace(-2, 10, 13)
# gamma_range = np.logspace(-3, -2, 13)
# param_grid = dict(kernel=['rbf'],gamma=gamma_range, C=C_range)


# tree_param_grid = { 'min_samples_split': list((3,6,9)),'n_estimators':list((10,50,100))}

# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.012],
#                      'C': [0.01,1,150]}]

# scores = ['precision', 'recall']

# for score in scores:
#     print("# Tuning hyper-parameters for %s" % score)
#     print()

#     clf = GridSearchCV(
#         SVC(), tuned_parameters, scoring='%s_macro' % score,
#     )
#     clf.fit(train_data, train_label)

#     print("Best parameters set found on development set:")
#     print()
#     print(clf.best_params_)
#     print()
#     print("Grid scores on development set:")
#     print()
#     means = clf.cv_results_['mean_test_score']
#     stds = clf.cv_results_['std_test_score']
#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):
#         print("%0.3f (+/-%0.03f) for %r"
#               % (mean, std * 2, params))
#     print()

#     print("Detailed classification report:")
#     print()
#     print("The model is trained on the full development set.")
#     print("The scores are computed on the full evaluation set.")
#     print()
#     y_true, y_pred = y_test, clf.predict(X_test)
#     print(classification_report(y_true, y_pred))
#     print()

# # Note the problem is too easy: the hyperparameter plateau is too flat and the
# # output model is the same for precision and recall with ties in quality.